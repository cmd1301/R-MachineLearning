dados_treino <- dados_clientes[indice,] # fatiar o df
dim(dados_treino)
dim(dados_clientes)
table(dados_treino$inadimplente)
# Porcentagens no dataset de treino
prop.table(table(dados_treino$inadimplente))
# Número de registros no dataset de treino
dim(dados_treino)
# Comparamos as porcentagens entre as classes de treinamento e dados originais
compara_dados <- cbind(prop.table(table(dados_treino$inadimplente)),
prop.table(table(dados_clientes$inadimplente)))
colnames(compara_dados) <- c('treinamento', 'original')
compara_dados
melt_compara_dados <- melt(compara_dados)
melt_compara_dados
# Tudo que não está no dataset de treinamento está no de teste (sinal de -)
dados_teste <- dados_clientes[-indice, ]
# Construindo a primeira versão do modelo
modelo_v1 <- randomForest(inadimplente ~ ., data = dados_treino)
dim(dados_treino)
# Tudo que não está no dataset de treinamento está no de teste (sinal de -)
dados_teste <- dados_clientes[-indice, ]
dados_teste <- dados_clientes[-indice, ]
dim(dados_treino)
# Número de registros no dataset de treino
dim(dados_treino)
# Número de registros no dataset de treino
dim(dados_treino)
dim(dados_treino)
modelo_v1
# Avaliando o modelo
plot(modelo_v1)
# Previsões com dados de teste
previsoes_v1 <- predict(modelo_v1, dados_teste)
# Confusion Matrix
cm_v1 <- caret::confusionMatrix(previsoes_v1, dados_teste$inadimplente, positive = "1")
cm_v1
y <- dados_teste$inadimplente
y_pred_v1 <- previsoes_v1
precision <- posPredValue(y_pred_v1, y)
precision
recall <- sensitivity(y_pred_v1)
recall
F1 <- (2*precision*recall)/(precision*recall)
F1
y <- dados_teste$inadimplente
y_pred_v1 <- previsoes_v1
precision <- posPredValue(y_pred_v1, y)
precision
recall <- sensitivity(y_pred_v1, y)
recall
F1 <- (2*precision*recall)/(precision*recall)
F1
# Balanceamento de classe
install.packages("DMwR")
library(DMwR)
# Balanceamento de classe
install.packages("DMwR2")
library(DMwR2)
# Aplicando o SMOTE: Synthethic Minority Over-sampling Technique
table(dados_treino$inadimplente)
prop.table(table(dados_treino$inadimplente))
set.seed(9560)
dados_treino_bal <- SMOTE(inadimplente ~ ., data = dados_treino)
# Balanceamento de classe
install.packages("performanceEstimation")
dados_treino_bal <- performanceEstimation::SMOTE(inadimplente ~ ., data = dados_treino)
dados_treino_bal <- SMOTE(inadimplente ~ ., data = dados_treino)
table(dados_treino_bal$inadimplente)
dados_treino_bal <- smote(inadimplente ~ ., data = dados_treino)
# Balanceamento de classe
install.packages("smotefamily")
library(smotefamily)
dados_treino_bal <- SMOTE(inadimplente ~ ., data = dados_treino)
# Aplicando o SMOTE: Synthethic Minority Over-sampling Technique
table(dados_treino$inadimplente)
prop.table(table(dados_treino$inadimplente))
dados_treino_bal <- SMOTE(inadimplente ~ ., data = dados_treino)
dados_treino_bal <- SMOTE(inadimplente ~ ., dados_treino)
dados_treino_bal <- SMOTE(inadimplente ~ ., data=dados_treino)
table(dados_treino_bal$inadimplente)
precision
setwd("C:/Users/Carlos Magno/Documents/PowerBI/Cap15")
getwd()
install.packages("Amelia") # funções para tratar valores ausentes
install.packages("caret") # construir modelos de ML e interpretar dados
install.packages("ggplot2")
install.packages("dplyr") # tratar dados
install.packages("reshape") # mudar a forma de alguns dados
install.packages("randomForest") # ML
install.packages("e1071") # ML
library(Amelia)
library(ggplot2)
library(caret)
library(dplyr)
library(reshape)
library(randomForest)
library(e1071)
# Carregando o dataset
dados_clientes <- read.csv("dados/dataset.csv")
# Removendo a primeira coluna: ID
dados_clientes$ID <- NULL
colnames(dados_clientes)[24] <- "inadimplente"
# Verificando valores ausentes e removendo do dataset
sapply(dados_clientes, function(x) sum(is.na(x)))
dados_clientes <- na.omit(dados_clientes)
colnames(dados_clientes)[2] <- "genero"
colnames(dados_clientes)[3] <- "escolaridade"
colnames(dados_clientes)[4] <- "estado_civil"
colnames(dados_clientes)[5] <- "idade"
dados_clientes$genero <- cut(dados_clientes$genero,
c(0,1,2),
labels = c("masculino", "feminino"))
# Escolaridade
dados_clientes$escolaridade <- cut(dados_clientes$escolaridade,
c(0,1,2,3,4),
labels = c('posgrad', 'grad', 'ensino_medio', 'outros'))
# Estado Civil
dados_clientes$estado_civil <- cut(dados_clientes$estado_civil,
c(-1,0,1,2,3),
labels = c('desconhecido', 'casado', 'solteiro', 'outro'))
dados_clientes$idade <- cut(dados_clientes$idade,
c(0,30,50,100),
labels = c('jovem', 'adulto', 'idoso'))
dados_clientes$PAY_0 <- as.factor(dados_clientes$PAY_0)
dados_clientes$PAY_2 <- as.factor(dados_clientes$PAY_2)
dados_clientes$PAY_3 <- as.factor(dados_clientes$PAY_3)
dados_clientes$PAY_4 <- as.factor(dados_clientes$PAY_4)
dados_clientes$PAY_5 <- as.factor(dados_clientes$PAY_5)
dados_clientes$PAY_6 <- as.factor(dados_clientes$PAY_6)
sapply(dados_clientes, function(x) sum(is.na(x)))
dados_clientes <- na.omit(dados_clientes)
dados_clientes$inadimplente <- as.factor(dados_clientes$inadimplente)
# Total de inadimplentes versus não-inadimplentes
# função table calcula proporções de uma variável
table(dados_clientes$inadimplente)
prop.table(table(dados_clientes$inadimplente))
# Set seed (random number generation)
set.seed(12345)
# Amostragem estratificada
# Seleciona as linhas de acordo com a variável inadimplente como strata
indice <- createDataPartition(dados_clientes$inadimplente, p = 0.75, list = FALSE)
# Definimos os dados de treinamento como subconjunto do conjunto de dados original
# com números de índice de linha (conforme identificado acima) e todas as colunas
dados_treino <- dados_clientes[indice,] # fatiar o df
dim(dados_treino)
table(dados_treino$inadimplente)
# Porcentagens no dataset de treino
prop.table(table(dados_treino$inadimplente))
# Comparamos as porcentagens entre as classes de treinamento e dados originais
compara_dados <- cbind(prop.table(table(dados_treino$inadimplente)),
prop.table(table(dados_clientes$inadimplente)))
compara_dados
melt_compara_dados <- melt(compara_dados)
melt_compara_dados
# Tudo que não está no dataset de treinamento está no de teste (sinal de -)
dados_teste <- dados_clientes[-indice, ]
# Construindo a primeira versão do modelo
modelo_v1 <- randomForest(inadimplente ~ ., data = dados_treino)
modelo_v1
# Avaliando o modelo
plot(modelo_v1)
# Previsões com dados de teste
previsoes_v1 <- predict(modelo_v1, dados_teste)
# Confusion Matrix
cm_v1 <- caret::confusionMatrix(previsoes_v1, dados_teste$inadimplente, positive = "1")
cm_v1
# Calculando Precision, Recall e F1-Score, métricas de avaliação do modelo preditivo
y <- dados_teste$inadimplente
y_pred_v1 <- previsoes_v1
precision <- posPredValue(y_pred_v1, y)
precision
recall <- sensitivity(y_pred_v1, y)
recall
F1 <- (2*precision*recall)/(precision*recall)
F1
# Balanceamento de classe
install.packages("DMwR")
library(performanceEstimation)
dados_treino_bal <- smote(inadimplente ~ ., data=dados_treino)
table(dados_treino_bal$inadimplente)
set.seed(9560)
dados_treino_bal <- smote(inadimplente ~ ., data=dados_treino)
table(dados_treino_bal$inadimplente)
prop.table(table(dados_treino_bal$inadimplente))
# Construindo a segunda versão do modelo
modelo_v2 <- randomForest(inadimplente ~ ., data=dados_treino_bal)
modelo_v2
# Avaliando o modelo
plot(modelo_v2)
# Previsões com dados de teste
previsoes_v2 <- predict(modelo_v2, dados_teste)
confusionMatrix
# Confusion Matrix
cm_v2 <- caret::confusionMatrix(previsoes_v2, dados_teste$inadimplente, positive = "1")
cm_v2
y <- dados_teste$inadimplente
y_pred_v2 <- previsoes_v2
precision <- posPredValue(y_pred_v2, y)
precision
recall <- sensitivity(y_pred_v2, y)
recall
F1 <- (2*precision*recall)/(precision*recall)
F1
F1 <- (2*precision*recall)/(precision+recall)
F1
y <- dados_teste$inadimplente
y_pred_v1 <- previsoes_v1
precision <- posPredValue(y_pred_v1, y)
precision
recall <- sensitivity(y_pred_v1, y)
recall
F1 <- (2*precision*recall)/(precision+recall)
F1
varImpPlot(modelo_v2)
varImpPlot(modelo_v2)
# Obtendo as variáveis mais importantes
imp_var <- importance(modelo_v2)
varImportance <- data.frame(variables = row.names(imp_var),
Importance = round(imp_var[ ,"MeanDecreaseGini"],2))
# Criando o rank de variáveis baseado na importância
rankImportance <- varImportance %>%
mutate(Rank = paste0('#', dense_rank(desc(Importance))))
# Criando o rank de variáveis baseado na importância
rankImportance <- varImportance %>%
mutate(Rank = paste0('#', dense_rank(desc(Importance))))
# Usando ggplot2 para visualizar a importância relativa das variáveis
ggplot(rankImportance,
aes(x = reorder(Variables, Importance),
y = Importance,
fill = Importance)) +
geom_bar(stat = 'identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust = 0,
vjust = 0.55,
size = 4
colour = 'red') +
labs(x = 'Variables') +
coord_flip()
# Usando ggplot2 para visualizar a importância relativa das variáveis
ggplot(rankImportance,
aes(x = reorder(Variables, Importance),
y = Importance,
fill = Importance)) +
geom_bar(stat = 'identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust = 0,
vjust = 0.55,
size = 4,
colour = 'red') +
labs(x = 'Variables') +
coord_flip()
# Usando ggplot2 para visualizar a importância relativa das variáveis
ggplot(rankImportance,
aes(x = reorder(Variables, Importance),
y = Importance,
fill = Importance)) +
geom_bar(stat = 'identity') +
geom_text(aes(x = variables, y = 0.5, label = Rank),
hjust = 0,
vjust = 0.55,
size = 4,
colour = 'red') +
labs(x = 'Variables') +
coord_flip()
varImportance <- data.frame(Variables = row.names(imp_var),
Importance = round(imp_var[ ,"MeanDecreaseGini"],2))
# Criando o rank de variáveis baseado na importância
rankImportance <- varImportance %>%
mutate(Rank = paste0('#', dense_rank(desc(Importance))))
# Criando o rank de variáveis baseado na importância
rankImportance <- varImportance %>%
mutate(Rank = paste0('#', dense_rank(desc(Importance))))
# Usando ggplot2 para visualizar a importância relativa das variáveis
ggplot(rankImportance,
aes(x = reorder(Variables, Importance),
y = Importance,
fill = Importance)) +
geom_bar(stat = 'identity') +
geom_text(aes(x = variables, y = 0.5, label = Rank),
hjust = 0,
vjust = 0.55,
size = 4,
colour = 'red') +
labs(x = 'Variables') +
coord_flip()
# Usando ggplot2 para visualizar a importância relativa das variáveis
ggplot(rankImportance,
aes(x = reorder(Variables, Importance),
y = Importance,
fill = Importance)) +
geom_bar(stat = 'identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust = 0,
vjust = 0.55,
size = 4,
colour = 'red') +
labs(x = 'Variables') +
coord_flip()
modelo_v3 <- randomForest(inadimplente ~ PAY_0 + PAY_2 + PAY_3 + PAY_AMT1 + PAY_AMT2 + PAY_5 + BILL_AMT1, data = dados_treino_bal)
modelo_v3
# Avaliando o modelo
plot(modelo_v3)
# Previsões com dados de teste
previsoes_v3 <- predict(modelo_v3, dados_teste)
# Confusion Matrix
cm_v3 <- caret::confusionMatrix(previsoes_v3, dados_teste$inadimplente, positive = "1")
cm_v3
# Calculando Precision, Recall e F1-Score, métricas de avaliação do modelo preditivo
y <- dados_teste$inadimplente
y_pred_v3 <- previsoes_v3
precision <- posPredValue(y_pred_v3, y)
precision
recall <- sensitivity(y_pred_v3, y)
recall
F1 <- (2*precision*recall)/(precision+recall)
F1
# Salvando o modelo em disco
saveRDS(modelo_v3, file = 'modelo/modelo_v3.rds')
# Definindo a pasta de trabalho
setwd("C:/Users/Carlos Magno/Documents/PowerBI/Cap15")
getwd()
# Salvando o modelo em disco
saveRDS(modelo_v3, file = 'modelo/modelo_v3.rds')
# Salvando o modelo em disco
saveRDS(modelo_v3, file = 'modelo/modelo_v3.rds')
# Salvando o modelo em disco
saveRDS(modelo_v3, file = 'modelo_v3.rds')
# Carregando o modelo
modelo_final <- readRDS('modelo_v3.rds')
# Carregando o modelo
modelo_final <- readRDS('modelo_v3.rds')
PAY_0 <- c(0, 0, 0)
PAY_2 <- c(0, 0, 0)
PAY_3 <- c(1, 0, 0)
PAY_AMT1 <- c(1100, 1000, 1200)
PAY_AMT2 <- c(1500, 1300, 1150)
PAY_5 <- c(0, 0, 0)
BILL_AMT1 <- c(350, 420, 280)
# Concatena em um dataframe
novos_clientes <- data.frame(PAY_0, PAY_2, PAY_3, PAY_AMT1, PAY_AMT2, PAY_5, BILL_AMT1)
View(novos_clientes)
# Previsões
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
str(novos_clientes)
novos_clientes$PAY_0 <- factor(novos_clientes$PAY_0, levels = levels(dados_treino_bal$PAY_0))
novos_clientes$PAY_2 <- factor(novos_clientes$PAY_2, levels = levels(dados_treino_bal$PAY_2))
novos_clientes$PAY_3 <- factor(novos_clientes$PAY_3, levels = levels(dados_treino_bal$PAY_3))
novos_clientes$PAY_5 <- factor(novos_clientes$PAY_5, levels = levels(dados_treino_bal$PAY_5))
str(novos_clientes)
# Previsões
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
View(novos_clientes)
View(previsoes_novo_cliente)
# Previsões
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
View(previsoes_novo_cliente)
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
View(previsoes_novo_cliente)
portance),
y = Importance,
fill = Importance)) +
geom_bar(stat = 'identity') +
geom_text(aes(x = Variables, y = 0.5, label = Rank),
hjust = 0,
vjust = 0.55,
size = 4,
colour = 'red') +
labs(x = 'Variables') +
coord_flip()
# Construindo a terceira visão do modelo apenas com as variáveis mais importantes
colnames(dados_treino_bal)
modelo_v3 <- randomForest(inadimplente ~ PAY_0 + PAY_2 + PAY_3 + PAY_AMT1 + PAY_AMT2 + PAY_5 + BILL_AMT1, data = dados_treino_bal)
modelo_v3
# Avaliando o modelo
plot(modelo_v3)
# Previsões com dados de teste
previsoes_v3 <- predict(modelo_v3, d
# Carregando o modelo
modelo_final <- readRDS('modelo_v3.rds')
setwd("C:/Users/Carlos Magno/Documents/PowerBI/Cap15")
getwd()
library(Amelia)
library(ggplot2)
library(caret)
library(dplyr)
library(reshape)
library(randomForest)
library(e1071)
# Carregando o dataset
dados_clientes <- read.csv("dados/dataset.csv")
# Removendo a primeira coluna: ID
dados_clientes$ID <- NULL
colnames(dados_clientes)[24] <- "inadimplente"
# Verificando valores ausentes e removendo do dataset
sapply(dados_clientes, function(x) sum(is.na(x)))
missmap(dados_clientes, main = "Valores Missing Observados")
dados_clientes <- na.omit(dados_clientes)
colnames(dados_clientes)[2] <- "genero"
colnames(dados_clientes)[3] <- "escolaridade"
colnames(dados_clientes)[4] <- "estado_civil"
colnames(dados_clientes)[5] <- "idade"
dados_clientes$genero <- cut(dados_clientes$genero,
c(0,1,2),
labels = c("masculino", "feminino"))
# Escolaridade
dados_clientes$escolaridade <- cut(dados_clientes$escolaridade,
c(0,1,2,3,4),
labels = c('posgrad', 'grad', 'ensino_medio', 'outros'))
# Estado Civil
dados_clientes$estado_civil <- cut(dados_clientes$estado_civil,
c(-1,0,1,2,3),
labels = c('desconhecido', 'casado', 'solteiro', 'outro'))
dados_clientes$idade <- cut(dados_clientes$idade,
c(0,30,50,100),
labels = c('jovem', 'adulto', 'idoso'))
dados_clientes$PAY_0 <- as.factor(dados_clientes$PAY_0)
dados_clientes$PAY_2 <- as.factor(dados_clientes$PAY_2)
dados_clientes$PAY_3 <- as.factor(dados_clientes$PAY_3)
dados_clientes$PAY_4 <- as.factor(dados_clientes$PAY_4)
dados_clientes$PAY_5 <- as.factor(dados_clientes$PAY_5)
dados_clientes$PAY_6 <- as.factor(dados_clientes$PAY_6)
sapply(dados_clientes, function(x) sum(is.na(x)))
dados_clientes <- na.omit(dados_clientes)
dados_clientes$inadimplente <- as.factor(dados_clientes$inadimplente)
# Total de inadimplentes versus não-inadimplentes
# função table calcula proporções de uma variável
table(dados_clientes$inadimplente)
prop.table(table(dados_clientes$inadimplente))
# Set seed (random number generation)
set.seed(12345)
# Amostragem estratificada
# Seleciona as linhas de acordo com a variável inadimplente como strata
indice <- createDataPartition(dados_clientes$inadimplente, p = 0.75, list = FALSE)
# Definimos os dados de treinamento como subconjunto do conjunto de dados original
# com números de índice de linha (conforme identificado acima) e todas as colunas
dados_treino <- dados_clientes[indice,] # fatiar o df
table(dados_treino$inadimplente)
# Porcentagens no dataset de treino
prop.table(table(dados_treino$inadimplente))
# Comparamos as porcentagens entre as classes de treinamento e dados originais
compara_dados <- cbind(prop.table(table(dados_treino$inadimplente)),
prop.table(table(dados_clientes$inadimplente)))
colnames(compara_dados) <- c('treinamento', 'original')
compara_dados
melt_compara_dados <- melt(compara_dados)
melt_compara_dados
# Tudo que não está no dataset de treinamento está no de teste (sinal de -)
dados_teste <- dados_clientes[-indice, ]
library(performanceEstimation)
# Aplicando o SMOTE: Synthethic Minority Over-sampling Technique
table(dados_treino$inadimplente)
prop.table(table(dados_treino$inadimplente))
set.seed(9560)
dados_treino_bal <- smote(inadimplente ~ ., data=dados_treino)
table(dados_treino_bal$inadimplente)
prop.table(table(dados_treino_bal$inadimplente))
# Construindo a terceira visão do modelo apenas com as variáveis mais importantes
colnames(dados_treino_bal)
modelo_v3 <- randomForest(inadimplente ~ PAY_0 + PAY_2 + PAY_3 + PAY_AMT1 + PAY_AMT2 + PAY_5 + BILL_AMT1, data = dados_treino_bal)
modelo_v3
# Previsões com dados de teste
previsoes_v3 <- predict(modelo_v3, dados_teste)
# Confusion Matrix
cm_v3 <- caret::confusionMatrix(previsoes_v3, dados_teste$inadimplente, positive = "1")
cm_v3
# Salvando o modelo em disco
saveRDS(modelo_v3, file = 'modelo_v3.rds')
# Carregando o modelo
modelo_final <- readRDS('modelo_v3.rds')
PAY_0 <- c(0, 0, 0)
PAY_2 <- c(0, 0, 0)
PAY_3 <- c(1, 0, 0)
PAY_AMT1 <- c(1100, 1000, 1200)
PAY_AMT2 <- c(1500, 1300, 1150)
PAY_5 <- c(0, 0, 0)
BILL_AMT1 <- c(350, 420, 280)
# Concatena em um dataframe
novos_clientes <- data.frame(PAY_0, PAY_2, PAY_3, PAY_AMT1, PAY_AMT2, PAY_5, BILL_AMT1)
novos_clientes$PAY_0 <- factor(novos_clientes$PAY_0, levels = levels(dados_treino_bal$PAY_0))
novos_clientes$PAY_2 <- factor(novos_clientes$PAY_2, levels = levels(dados_treino_bal$PAY_2))
novos_clientes$PAY_3 <- factor(novos_clientes$PAY_3, levels = levels(dados_treino_bal$PAY_3))
novos_clientes$PAY_5 <- factor(novos_clientes$PAY_5, levels = levels(dados_treino_bal$PAY_5))
str(novos_clientes)
# Previsões
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
View(previsoes_novo_cliente)
table(previsoes_novo_cliente)
# Previsões
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
View(previsoes_novo_cliente)
View(previsoes_novo_cliente)
pvnc <- as.numeric(previsoes_novo_cliente)
View(pvnc)
str(novos_clientes)
# Checando os tipos de dados
str(dados_treino_bal)
# Convertendo os tipos de dados
novos_clientes$PAY_0 <- factor(novos_clientes$PAY_0, levels = levels(dados_treino_bal$PAY_0))
novos_clientes$PAY_2 <- factor(novos_clientes$PAY_2, levels = levels(dados_treino_bal$PAY_2))
novos_clientes$PAY_3 <- factor(novos_clientes$PAY_3, levels = levels(dados_treino_bal$PAY_3))
novos_clientes$PAY_5 <- factor(novos_clientes$PAY_5, levels = levels(dados_treino_bal$PAY_5))
str(novos_clientes)
# Previsões
previsoes_novo_cliente <- predict(modelo_final, novos_clientes)
View(previsoes_novo_cliente)
table(previsoes_novo_cliente$inadimplente)
enframe(previsoes_novo_cliente)
install.packages("tibble")
install.packages("tibble")
library(tibble)
enframe(previsoes_novo_cliente)
